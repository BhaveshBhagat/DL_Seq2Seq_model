# -*- coding: utf-8 -*-
"""Flask_LanguageTranslation_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o3NcvVw8FpWJ42h3Zc4IMJnFdQzj7urv
"""

!pip install flask-ngrok

ME_tokens = {' ': 0,
 '!': 1,
 '"': 2,
 '$': 3,
 "'": 4,
 ',': 5,
 '-': 6,
 '.': 7,
 '/': 8,
 '0': 9,
 '1': 10,
 '2': 11,
 '3': 12,
 '4': 13,
 '5': 14,
 '6': 15,
 '7': 16,
 '8': 17,
 '9': 18,
 ':': 19,
 '?': 20,
 'A': 21,
 'B': 22,
 'C': 23,
 'D': 24,
 'E': 25,
 'F': 26,
 'G': 27,
 'H': 28,
 'I': 29,
 'J': 30,
 'K': 31,
 'L': 32,
 'M': 33,
 'N': 34,
 'O': 35,
 'P': 36,
 'Q': 37,
 'R': 38,
 'S': 39,
 'T': 40,
 'U': 41,
 'V': 42,
 'W': 43,
 'Y': 44,
 'a': 45,
 'b': 46,
 'c': 47,
 'd': 48,
 'e': 49,
 'f': 50,
 'g': 51,
 'h': 52,
 'i': 53,
 'j': 54,
 'k': 55,
 'l': 56,
 'm': 57,
 'n': 58,
 'o': 59,
 'p': 60,
 'q': 61,
 'r': 62,
 's': 63,
 't': 64,
 'u': 65,
 'v': 66,
 'w': 67,
 'x': 68,
 'y': 69,
 'z': 70}

HE_tokens = {' ': 0,
 '!': 1,
 '"': 2,
 '$': 3,
 "'": 4,
 ',': 5,
 '-': 6,
 '.': 7,
 '0': 8,
 '1': 9,
 '2': 10,
 '3': 11,
 '4': 12,
 '5': 13,
 '6': 14,
 '7': 15,
 '8': 16,
 '9': 17,
 ':': 18,
 '?': 19,
 'A': 20,
 'B': 21,
 'C': 22,
 'D': 23,
 'E': 24,
 'F': 25,
 'G': 26,
 'H': 27,
 'I': 28,
 'J': 29,
 'K': 30,
 'L': 31,
 'M': 32,
 'N': 33,
 'O': 34,
 'P': 35,
 'Q': 36,
 'R': 37,
 'S': 38,
 'T': 39,
 'U': 40,
 'V': 41,
 'W': 42,
 'Y': 43,
 'a': 44,
 'b': 45,
 'c': 46,
 'd': 47,
 'e': 48,
 'f': 49,
 'g': 50,
 'h': 51,
 'i': 52,
 'j': 53,
 'k': 54,
 'l': 55,
 'm': 56,
 'n': 57,
 'o': 58,
 'p': 59,
 'q': 60,
 'r': 61,
 's': 62,
 't': 63,
 'u': 64,
 'v': 65,
 'w': 66,
 'x': 67,
 'y': 68,
 'z': 69}

FE_tokens = {' ': 0,
 '!': 1,
 '$': 2,
 '%': 3,
 '&': 4,
 "'": 5,
 ',': 6,
 '-': 7,
 '.': 8,
 '0': 9,
 '1': 10,
 '2': 11,
 '3': 12,
 '5': 13,
 '6': 14,
 '7': 15,
 '8': 16,
 '9': 17,
 ':': 18,
 '?': 19,
 'A': 20,
 'B': 21,
 'C': 22,
 'D': 23,
 'E': 24,
 'F': 25,
 'G': 26,
 'H': 27,
 'I': 28,
 'J': 29,
 'K': 30,
 'L': 31,
 'M': 32,
 'N': 33,
 'O': 34,
 'P': 35,
 'Q': 36,
 'R': 37,
 'S': 38,
 'T': 39,
 'U': 40,
 'V': 41,
 'W': 42,
 'Y': 43,
 'a': 44,
 'b': 45,
 'c': 46,
 'd': 47,
 'e': 48,
 'f': 49,
 'g': 50,
 'h': 51,
 'i': 52,
 'j': 53,
 'k': 54,
 'l': 55,
 'm': 56,
 'n': 57,
 'o': 58,
 'p': 59,
 'q': 60,
 'r': 61,
 's': 62,
 't': 63,
 'u': 64,
 'v': 65,
 'w': 66,
 'x': 67,
 'y': 68,
 'z': 69,
 'é': 70}

M_tokens = {'\t': 0,
 '\n': 1,
 ' ': 2,
 '!': 3,
 '"': 4,
 '$': 5,
 ',': 6,
 '-': 7,
 '.': 8,
 ':': 9,
 '?': 10,
 'ँ': 11,
 'ं': 12,
 'ः': 13,
 'अ': 14,
 'आ': 15,
 'इ': 16,
 'ई': 17,
 'उ': 18,
 'ऊ': 19,
 'ऋ': 20,
 'ए': 21,
 'ऐ': 22,
 'ऑ': 23,
 'ओ': 24,
 'औ': 25,
 'क': 26,
 'ख': 27,
 'ग': 28,
 'घ': 29,
 'च': 30,
 'छ': 31,
 'ज': 32,
 'झ': 33,
 'ञ': 34,
 'ट': 35,
 'ठ': 36,
 'ड': 37,
 'ढ': 38,
 'ण': 39,
 'त': 40,
 'थ': 41,
 'द': 42,
 'ध': 43,
 'न': 44,
 'प': 45,
 'फ': 46,
 'ब': 47,
 'भ': 48,
 'म': 49,
 'य': 50,
 'र': 51,
 'ल': 52,
 'ळ': 53,
 'व': 54,
 'श': 55,
 'ष': 56,
 'स': 57,
 'ह': 58,
 '़': 59,
 'ा': 60,
 'ि': 61,
 'ी': 62,
 'ु': 63,
 'ू': 64,
 'ृ': 65,
 'ॅ': 66,
 'े': 67,
 'ै': 68,
 'ॉ': 69,
 'ो': 70,
 'ौ': 71,
 '्': 72,
 '।': 73,
 '०': 74,
 '१': 75,
 '२': 76,
 '३': 77,
 '४': 78,
 '५': 79,
 '६': 80,
 '७': 81,
 '८': 82,
 '९': 83,
 '\u200d': 84}

F_tokens = {'\t': 0,
 '\n': 1,
 ' ': 2,
 '!': 3,
 '$': 4,
 '%': 5,
 '&': 6,
 "'": 7,
 '(': 8,
 ')': 9,
 ',': 10,
 '-': 11,
 '.': 12,
 '0': 13,
 '1': 14,
 '2': 15,
 '3': 16,
 '5': 17,
 '8': 18,
 '9': 19,
 ':': 20,
 '?': 21,
 'A': 22,
 'B': 23,
 'C': 24,
 'D': 25,
 'E': 26,
 'F': 27,
 'G': 28,
 'H': 29,
 'I': 30,
 'J': 31,
 'K': 32,
 'L': 33,
 'M': 34,
 'N': 35,
 'O': 36,
 'P': 37,
 'Q': 38,
 'R': 39,
 'S': 40,
 'T': 41,
 'U': 42,
 'V': 43,
 'Y': 44,
 'a': 45,
 'b': 46,
 'c': 47,
 'd': 48,
 'e': 49,
 'f': 50,
 'g': 51,
 'h': 52,
 'i': 53,
 'j': 54,
 'k': 55,
 'l': 56,
 'm': 57,
 'n': 58,
 'o': 59,
 'p': 60,
 'q': 61,
 'r': 62,
 's': 63,
 't': 64,
 'u': 65,
 'v': 66,
 'x': 67,
 'y': 68,
 'z': 69,
 '\xa0': 70,
 '«': 71,
 '»': 72,
 'À': 73,
 'Ç': 74,
 'É': 75,
 'Ê': 76,
 'à': 77,
 'â': 78,
 'ç': 79,
 'è': 80,
 'é': 81,
 'ê': 82,
 'ë': 83,
 'î': 84,
 'ï': 85,
 'ô': 86,
 'ù': 87,
 'û': 88,
 'œ': 89,
 '\u2009': 90,
 '’': 91,
 '\u202f': 92}

H_tokens = {'\t': 0,
 '\n': 1,
 ' ': 2,
 '!': 3,
 '"': 4,
 '(': 5,
 ')': 6,
 ',': 7,
 '-': 8,
 '.': 9,
 ':': 10,
 '?': 11,
 'A': 12,
 'B': 13,
 'I': 14,
 '|': 15,
 'ँ': 16,
 'ं': 17,
 'ः': 18,
 'अ': 19,
 'आ': 20,
 'इ': 21,
 'ई': 22,
 'उ': 23,
 'ऊ': 24,
 'ऋ': 25,
 'ए': 26,
 'ऐ': 27,
 'ऑ': 28,
 'ओ': 29,
 'औ': 30,
 'क': 31,
 'ख': 32,
 'ग': 33,
 'घ': 34,
 'च': 35,
 'छ': 36,
 'ज': 37,
 'झ': 38,
 'ञ': 39,
 'ट': 40,
 'ठ': 41,
 'ड': 42,
 'ढ': 43,
 'ण': 44,
 'त': 45,
 'थ': 46,
 'द': 47,
 'ध': 48,
 'न': 49,
 'प': 50,
 'फ': 51,
 'ब': 52,
 'भ': 53,
 'म': 54,
 'य': 55,
 'र': 56,
 'ल': 57,
 'व': 58,
 'श': 59,
 'ष': 60,
 'स': 61,
 'ह': 62,
 '़': 63,
 'ा': 64,
 'ि': 65,
 'ी': 66,
 'ु': 67,
 'ू': 68,
 'ृ': 69,
 'ॅ': 70,
 'े': 71,
 'ै': 72,
 'ॉ': 73,
 'ो': 74,
 'ौ': 75,
 '्': 76,
 'ख़': 77,
 'ज़': 78,
 'ड़': 79,
 'ढ़': 80,
 '।': 81,
 '०': 82,
 '१': 83,
 '२': 84,
 '४': 85,
 '५': 86,
 '६': 87,
 '७': 88,
 '८': 89,
 '९': 90,
 '\u200d': 91}

def Input_encoder(input_sentence , max_len , Uniq_char , input_token):     
      encoder_input_data = np.zeros(
          (len(input_sentence), max_len, Uniq_char),
          dtype='float32')
      
      for i, input_text in enumerate(input_sentence):
          for t, char in enumerate(input_text):
              encoder_input_data[i, t, input_token[char]] = 1.
          encoder_input_data[i, t + 1:, input_token[' ']] = 1.

      return encoder_input_data

def decode_sequence(input_seq , encoder , decoder ,max_len , unq_vocab , target_token , input_token):
    
    reverse_input_char_index = dict(
    (i, char) for char, i in input_token.items())
    reverse_target_char_index = dict(
    (i, char) for char, i in target_token.items())
    
    
    # Encode the input as state vectors.
    states_value = encoder.predict(input_seq)

    # Generate empty target sequence of length 1.
    target_seq = np.zeros((1, 1, unq_vocab))
    # Populate the first character of target sequence with the start character.
    target_seq[0, 0, target_token['\t']] = 1.

    # Sampling loop for a batch of sequences
    # (to simplify, here we assume a batch of size 1).
    stop_condition = False
    decoded_sentence = ''
    while not stop_condition:
        output_tokens, h, c = decoder.predict(
            [target_seq] + states_value)

        # Sample a token
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_char = reverse_target_char_index[sampled_token_index]
        decoded_sentence += sampled_char

        # Exit condition: either hit max length
        # or find stop character.
        if (sampled_char == '\n' or
           len(decoded_sentence) > max_len):
            stop_condition = True

        # Update the target sequence (of length 1).
        target_seq = np.zeros((1, 1, unq_vocab))
        target_seq[0, 0, sampled_token_index] = 1.

        # Update states
        states_value = [h, c]

    return decoded_sentence



import numpy as np
import pandas as pd

from flask import Flask, render_template , request
from flask_ngrok import run_with_ngrok
from tensorflow.keras.models import load_model
from tensorflow.keras import Model
from tensorflow.keras.layers import Input 
import numpy as np

app = Flask(__name__, template_folder = '.')
run_with_ngrok(app)

M_encoder = load_model('/content/drive/My Drive/Colab Notebook/ENG2MAR_encoder.h5')

M_decoder = load_model('/content/drive/My Drive/Colab Notebook/ENG2MAR_decoder.h5')


H_encoder = load_model('/content/drive/My Drive/Colab Notebook/E2H_encoder.h5')

H_decoder = load_model('/content/drive/My Drive/Colab Notebook/E2H_decoder.h5')

F_encoder = load_model('/content/drive/My Drive/Colab Notebook/ENG2French_encoder.h5')

F_decoder = load_model('/content/drive/My Drive/Colab Notebook/ENG2French_decoder.h5')


@app.route('/')
def home():
  return render_template('LanguageTranslation_home.html')

@app.route('/content/ENG2French_home.html')
def redirect_page1():
   return render_template('ENG2French_home.html')

@app.route('/content/ENG2Marathi_home.html')
def redirect_page2():
   return render_template('ENG2Marathi_home.html') 

@app.route('/content/ENG2Hindi_home.html')
def redirect_page3():
   return render_template('ENG2Hindi_home.html')     

@app.route('/content/ENG2Marathi_home.html' , methods = ['POST','GET'])
def M_result():
  if request.method == 'POST':
      input = []
      Mresult = request.form['english']
      print(Mresult)
      input.append(Mresult)
      input_sent  =Input_encoder(input,19,71 ,ME_tokens)
      decoded_sentence = decode_sequence(input_sent[0:1],M_encoder , M_decoder , 42 ,85 , M_tokens ,ME_tokens)
      
  return render_template('ENG2Marathi_home.html',Input = Mresult ,result = decoded_sentence)

@app.route('/content/ENG2French_home.html' , methods = ['POST','GET'])
def F_result():
  if request.method == 'POST':
      input = []
      Fresult = request.form['english']
      print(Fresult)
      input.append(Fresult)
      input_sent  = Input_encoder(input, 16, 71 , FE_tokens)
      decoded_sentence = decode_sequence(input_sent[0:1],F_encoder,F_decoder,59,93 , F_tokens, FE_tokens)
  
  return render_template('ENG2French_home.html',Input = Fresult ,result = decoded_sentence) 

@app.route('/content/ENG2Hindi_home.html' , methods = ['POST','GET'])
def H_result():
  if request.method == 'POST':
      input = []
      Hresult = request.form['english']
      print(Hresult)
      input.append(Hresult)
      input_sent  = Input_encoder(input,44,70,HE_tokens)
      decoded_sentence = decode_sequence(input_sent[0:1],H_encoder,H_decoder,81,92 ,H_tokens ,HE_tokens)
    
  return render_template('ENG2Hindi_home.html' ,Input = Hresult, result = decoded_sentence)  

@app.route('/content/LanguageTranslation_home.html')
def back():
    return render_template('LanguageTranslation_home.html') 

app.run()